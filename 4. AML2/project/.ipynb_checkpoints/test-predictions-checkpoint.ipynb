{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in Results, best test accuracy is obtained with the multilayer fully connected network. We compute the predictions using the model on the test Overfeat features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import timeit\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the numpy .npz file\n",
    "with np.load('cifar4-test.npz', allow_pickle=False) as data:\n",
    "    cifar_data = dict(data.items())\n",
    "\n",
    "X_test = cifar_data['overfeat'].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 4096)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'hidden/kernel:0' shape=(4096, 64) dtype=float32_ref>\n",
      "<tf.Variable 'hidden/bias:0' shape=(64,) dtype=float32_ref>\n",
      "<tf.Variable 'output/kernel:0' shape=(64, 4) dtype=float32_ref>\n",
      "<tf.Variable 'output/bias:0' shape=(4,) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    # Create placeholders\n",
    "    X = tf.placeholder(dtype=tf.float32, shape=[None, 4096], name = 'X')\n",
    "    y = tf.placeholder(dtype=tf.int32, shape=[None], name = 'y')\n",
    "\n",
    "    # Create training placeholder\n",
    "    training = tf.placeholder(dtype=tf.bool, name = 'bool_training')\n",
    "\n",
    "    # Apply dropout\n",
    "    X = tf.layers.dropout(\n",
    "        X, rate=0.5, seed=0, training=training)\n",
    "    \n",
    "    # Hidden layer with 64 units\n",
    "    hidden = tf.layers.dense(\n",
    "        X, 64, activation=tf.nn.relu, # ReLU\n",
    "        kernel_initializer=tf.variance_scaling_initializer(scale=2, seed=0),\n",
    "        bias_initializer=tf.zeros_initializer(),\n",
    "        name='hidden'\n",
    "    )\n",
    "\n",
    "    # Apply dropout\n",
    "    hidden = tf.layers.dropout(\n",
    "        hidden, rate=0.5, seed=0, training=training)\n",
    "    \n",
    "    # Output layer with 4 units\n",
    "    logits = tf.layers.dense(\n",
    "        hidden, 4, activation=None, # No activation function\n",
    "        kernel_initializer=tf.variance_scaling_initializer(scale=1, seed=0),\n",
    "        bias_initializer=tf.zeros_initializer(),\n",
    "        name='output'\n",
    "    )\n",
    "\n",
    "    \n",
    "    # Get weights/biases of the hidden layer\n",
    "    with tf.variable_scope('hidden', reuse=True):\n",
    "        W1 = tf.get_variable('kernel')\n",
    "        b1 = tf.get_variable('bias')\n",
    "\n",
    "    # Get weights/biases of the output layer\n",
    "    with tf.variable_scope('output', reuse=True):\n",
    "        W2 = tf.get_variable('kernel')\n",
    "        b2 = tf.get_variable('bias')\n",
    "\n",
    "\n",
    "    # Loss fuction: mean cross-entropy with L2 regularization\n",
    "    mean_ce = tf.reduce_mean(\n",
    "        tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "            labels=y, logits=logits))\n",
    "\n",
    "    # Loss function with L2 term\n",
    "    l2_term = tf.nn.l2_loss(W1) + tf.nn.l2_loss(W2)\n",
    "    # Regularization strength\n",
    "    alpha = tf.placeholder(dtype=tf.float32, name='alpha')\n",
    "    # Loss function\n",
    "    loss = mean_ce + alpha * l2_term\n",
    "    # Gradient descent\n",
    "    lr = tf.placeholder(dtype=tf.float32, name='lr')\n",
    "    gd = tf.train.GradientDescentOptimizer(learning_rate=lr)\n",
    "    \n",
    "    # Minimize cross-entropy with L2 regularization - Training operation\n",
    "    train_op = gd.minimize(loss)\n",
    "\n",
    "    # Compute predictions and accuracy\n",
    "    predictions = tf.argmax(logits, axis=1, output_type=tf.int32)\n",
    "    is_correct = tf.equal(y, predictions)\n",
    "    accuracy = tf.reduce_mean(tf.cast(is_correct, dtype=tf.float32))\n",
    "\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "\n",
    "## seeing whether this thing works somehow. \n",
    "with graph.as_default():\n",
    "    # Get variables in the graph\n",
    "    for v in tf.trainable_variables():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph) as sess:\n",
    "    \n",
    "    # Restore variables from \"Multilayer fully-connected network\".ipynb\n",
    "    saver.restore(sess, \"/tmp/model.ckpt\")\n",
    "    \n",
    "    ### I have no idea how I found that. But it seems to work. \n",
    "    predictions_test = sess.run(predictions, feed_dict={\n",
    "                    X: X_test, \n",
    "                    training : False\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 2, 3, 2, 3, 3, 3, 0, 2, 3, 0, 1, 1, 0, 2, 3, 1, 2, 0, 1, 0,\n",
       "       1, 2, 3, 1, 2, 0, 2, 1, 0, 0, 2, 1, 3, 0, 1, 1, 1, 3, 2, 3, 0, 2,\n",
       "       2, 2, 1, 1, 1, 3, 3, 1, 0, 1, 2, 3, 0, 2, 0, 2, 0, 0, 0, 1, 2, 1,\n",
       "       3, 2, 0, 1, 3, 3, 3, 3, 3, 3, 3, 2, 3, 1, 3, 0, 2, 3, 3, 0, 2, 3,\n",
       "       3, 2, 2, 1, 1, 0, 1, 2, 0, 1, 3, 1, 3, 2, 1, 3, 3, 3, 1, 2, 1, 3,\n",
       "       0, 1, 1, 0, 3, 3, 2, 1, 2, 2, 1, 1, 2, 0, 2, 2, 3, 1, 1, 1, 0, 1,\n",
       "       0, 3, 2, 2, 2, 1, 1, 1, 0, 2, 3, 2, 1, 3, 3, 2, 1, 1, 1, 2, 2, 2,\n",
       "       3, 1, 3, 0, 3, 2, 0, 2, 0, 1, 2, 1, 0, 3, 3, 3, 0, 3, 0, 3, 0, 2,\n",
       "       1, 3, 2, 0, 1, 2, 1, 0, 1, 2, 3, 3, 1, 0, 3, 0, 2, 0, 2, 3, 1, 2,\n",
       "       3, 0, 3, 0, 3, 0, 1, 2, 1, 1, 2, 2, 1, 3, 1, 1, 3, 1, 0, 0, 0, 1,\n",
       "       1, 3, 3, 2, 1, 0, 3, 3, 0, 1, 2, 0, 2, 3, 1, 3, 2, 2, 2, 3, 1, 3,\n",
       "       1, 3, 3, 2, 1, 3, 3, 2, 2, 1, 2, 2, 3, 2, 2, 1, 1, 3, 3, 1, 3, 3,\n",
       "       1, 1, 1, 3, 3, 0, 1, 3, 0, 2, 0, 2, 1, 2, 2, 1, 0, 2, 0, 3, 3, 2,\n",
       "       0, 3, 3, 1, 1, 1, 0, 3, 2, 2, 3, 2, 0, 3, 1, 0, 3, 2, 3, 3, 1, 3,\n",
       "       1, 0, 2, 0, 0, 0, 2, 0, 2, 1, 2, 3, 0, 1, 3, 3, 3, 3, 3, 0, 1, 1,\n",
       "       0, 1, 3, 2, 3, 0, 1, 3, 1, 2, 3, 0, 0, 0, 2, 3, 1, 0, 2, 2, 0, 2,\n",
       "       3, 0, 3, 2, 3, 1, 0, 0, 3, 3, 3, 0, 0, 0, 3, 3, 0, 1, 3, 2, 2, 3,\n",
       "       0, 2, 3, 1, 2, 2, 1, 0, 2, 0, 2, 2, 1, 2, 2, 2, 0, 1, 2, 3, 2, 1,\n",
       "       1, 1, 0, 3, 1, 2, 3, 3, 3, 3, 3, 2, 2, 3, 1, 0, 2, 0, 0, 2, 3, 3,\n",
       "       3, 2, 0, 2, 3, 1, 1, 1, 0, 2, 1, 2, 3, 3, 0, 1, 0, 0, 2, 2, 2, 3,\n",
       "       3, 3, 3, 3, 0, 3, 3, 1, 1, 3, 1, 3, 1, 0, 0, 1, 2, 2, 1, 0, 2, 0,\n",
       "       0, 1, 1, 2, 1, 3, 1, 0, 3, 3, 0, 0, 3, 1, 0, 0, 3, 3, 2, 1, 1, 1,\n",
       "       1, 1, 0, 3, 1, 1, 2, 1, 0, 2, 0, 0, 2, 0, 1, 3, 0, 0, 3, 0, 3, 3,\n",
       "       3, 2, 0, 1, 3, 1, 3, 2, 3, 3, 0, 1, 0, 0, 2, 1, 1, 3, 3, 1, 3, 3,\n",
       "       2, 0, 3, 3, 3, 3, 2, 2, 3, 3, 1, 1, 1, 0, 3, 2, 1, 2, 1, 2, 3, 3,\n",
       "       1, 2, 3, 3, 3, 2, 3, 0, 3, 1, 2, 2, 3, 0, 0, 1, 2, 1, 1, 1, 2, 2,\n",
       "       1, 3, 2, 1, 2, 2, 2, 1, 2, 1, 3, 3, 3, 0, 2, 3, 0, 3, 1, 0, 2, 3,\n",
       "       3, 1, 0, 1, 0, 1, 1, 2, 0, 1, 1, 0, 1, 3, 1, 0, 1, 2, 2, 0, 0, 0,\n",
       "       3, 3, 3, 1, 2, 1, 1, 3, 2, 3, 1, 0, 2, 3, 3, 1, 2, 3, 0, 0, 1, 0,\n",
       "       0, 1, 3, 0, 2, 3, 3, 0, 2, 3, 0, 2, 3, 1, 1, 1, 1, 3, 1, 2, 0, 1,\n",
       "       1, 3, 2, 3, 2, 1, 1, 3, 2, 1, 2, 3, 1, 1, 1, 2, 0, 0, 1, 0, 0, 3,\n",
       "       1, 0, 0, 1, 0, 2, 0, 0, 1, 0, 3, 0, 1, 0, 3, 2, 0, 1, 0, 3, 0, 0,\n",
       "       1, 0, 1, 3, 3, 1, 1, 0, 1, 0, 3, 1, 1, 0, 3, 0, 0, 3, 1, 1, 0, 0,\n",
       "       2, 0, 1, 1, 3, 1, 2, 1, 0, 3, 3, 1, 2, 3, 2, 1, 1, 2, 2, 3, 0, 2,\n",
       "       0, 1, 1, 0, 2, 0, 0, 0, 1, 0, 2, 3, 3, 1, 0, 0, 0, 1, 0, 2, 1, 0,\n",
       "       2, 2, 0, 1, 0, 2, 0, 0, 0, 2, 1, 0, 2, 0, 0, 3, 0, 1, 1, 0, 0, 2,\n",
       "       1, 2, 3, 1, 0, 3, 0, 1, 1, 0, 1, 3, 3, 3, 3, 1, 2, 3, 2, 2, 2, 2,\n",
       "       0, 0, 3, 2, 1, 0, 2, 2, 0, 2, 2, 3, 1, 2, 3, 1, 0, 0, 2, 0, 1, 1,\n",
       "       2, 2, 1, 0, 3, 2, 1, 1, 3, 0, 1, 0, 2, 0, 2, 0, 3, 3, 1, 0, 0, 0,\n",
       "       3, 1, 1, 0, 0, 2, 3, 0, 1, 2, 0, 0, 0, 3, 2, 2, 1, 1, 0, 1, 0, 3,\n",
       "       2, 0, 2, 0, 1, 3, 0, 2, 0, 1, 0, 1, 2, 1, 3, 2, 1, 3, 2, 3, 2, 1,\n",
       "       1, 3, 3, 0, 0, 0, 1, 0, 3, 0, 1, 1, 2, 2, 3, 1, 2, 0, 0, 1, 3, 2,\n",
       "       2, 3, 3, 3, 2, 3, 1, 2, 1, 0, 3, 2, 2, 0, 0, 2, 3, 1, 1, 3, 1, 1,\n",
       "       0, 3, 3, 1, 2, 0, 3, 0, 2, 1, 3, 2, 3, 1, 0, 1, 3, 3, 3, 2, 1, 1,\n",
       "       3, 2, 3, 0, 3, 1, 0, 2, 2, 2, 0, 0, 3, 0, 3, 1, 0, 3, 2, 2, 2, 0,\n",
       "       1, 1, 3, 0, 0, 1, 1, 0, 3, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### saving\n",
    "\n",
    "np.save('test-predictions.npy', predictions_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
